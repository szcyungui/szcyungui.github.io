---
layout:     post
title:    2020-07-07-Web性能优化
date:       2020-07-07
author:     Yungui
header-img: img/post-bg-ios9-web.jpg
catalog: true
tags: 
    - 函数式编程
    - ES6
---
#  网络技术概况
## 延迟与带宽
1. 网络通信性能决定性的因素：延迟和带宽，大多数网站性能的瓶颈都是延迟，而不是带宽(看TCP UDP HTTP协议细节)！
---
2. 延迟分为：传输延迟（消息长度和链路速率的函数），传播延迟（信号传播距离和速度的函数），处理延迟(处理分组首部、检查位错误及确定分组目标所需的时间)，排队延迟(到来的分组排队等待处理的时间)

> 分组到达路由器。路由器必须检测分组的首部，以确定出站路由，并且还可能对数据进行检查，这些都要花时间。由于这些检查通常由硬件完成，因此相应的延迟一般非常短，但再短也还是存在。最后，如果分组到达的速度超过了路由器的处理能力，那么分组就要在入站缓冲区排队。数据在缓冲区排队等待的时间，当然就是**排队延迟**。

> 每个分组在通过网络时都会遇到这样或那样的延迟。发送端与接收端的距离越远，传播时间就越长。一路上经过的路由器越多，每个分组的处理和传输延迟就越多。最后，网络流量越拥挤，分组在入站缓冲区中被延迟的可能性就越大。

3. 缓存区爆满：排队延迟影响网络整体性能的一个形象的说法。
4. CDN（Content Delivery Network，内容分发网络）服务的用途很多，但最重要的就是通过把内容部署在全球各地，让用户从最近的服务器加载内容，大幅降低传播分组的时间。或许我们不能让数据传输得更快，但我们可以缩短服务器与用户之间的距离！把数据托管到 CDN 能够显著提高性能。
5. traceroute 命令，就能知道上网服务商的拓扑结构和速度。
```
$> traceroute google.com
// 在 Unix 平台上，可以在命令行运行 traceroute。
// 而在 Windows 平台中，相应的命令叫 tracert。
```
## TCP的构成
1. 因特网有两个核心协议：IP 和 TCP。IP，即 Internet Protocol（因特网协议），负责联网主机之间的路由选择和寻址；TCP，即 Transmission Control Protocol（传输控制协议），负责在不可靠的传输信道之上提供可靠的抽象层。TCP/IP 也常被称为“因特网协议套件”（Internet Protocol Suite）
---
2. 三次握手

所有 TCP 连接一开始都要经过三次握手。客户端与服务器在交换应用数据之前，必须就起始分组序列号，以及其他一些连接相关的细节达成一致。出于安全考虑，序列号由两端随机生成。
- SYN
客户端选择一个随机序列号 x，并发送一个 SYN 分组，其中可能还包括其他 TCP
标志和选项。
- SYN ACK
服务器给 x 加 1，并选择自己的一个随机序列号 y，追加自己的标志和选项，然
后返回响应。
- ACK
客户端给 x 和 y 加 1 并发送握手期间的最后一个 ACK 分组。

三次握手完成后，客户端与服务器之间就可以通信了。客户端可以在发送 ACK分组之后立即发送数据，而服务器必须等接收到ACK分组之后才能发送数据。

```
1. 三次握手带来的延迟使得每创建一个新 TCP 连接都要付出很大代价。而这也决定了提高 TCP 应用性能的关键，在于想办法重用连接。
2. 遗憾的是，连接并不是想重用就可以重用的。事实上，由于非常短的 TCP 连接在互联网上随处可见，握手阶段已经成为影响网络总延迟的一个重要因素。
3. 为解决这个问题， TFO（TCP Fast Open，TCP 快速打开）就是这样一种机制，它致力于减少新建 TCP连接带来的性能损失。
```
--- 
3. 拥塞预防及控制：“拥塞崩溃”的现象，这个现象会影响节点间带宽容量不对称的任何网络。

拥塞控制：Internet Protocol（IP） —— 纯 粹 的 数 据 报 协 议， 和 Transmission Control Protocol （TCP）——传输层协议，在一块使用时，由于传输层与数据报层之间的交互，会导致一些不常见的拥塞问题。特别是 IP 网关容易受到我们称为“拥塞崩溃”现象的严重影响，尤其是在这种网关连接不同带宽的网络时。

可能是往返时间超过了所有主机的最大中断间隔，于是相应的主机会在网络中制造越来越多的数据报副本，使得整个网络陷入瘫痪。最终，所有交换节点的缓冲区都将被填满，多出来的分组必须删掉。目前的分组往返时间已经设定为最大值。主机会把每个分组都发送好几次，结果每个分组的某个副本会抵达目标。这就是拥塞崩溃。

---

**3.1 流量控制**：流量控制是一种预防发送端过多向接收端发送数据的机制。否则，接收端可能因为忙碌、负载重或缓冲区既定而无法处理。

第一次建立连接时，两端都会使用自身系统的默认设置来发送 rwnd。**浏览网页**通常主要从服务器向客户端下载数据，因此客户端窗口更可能成为瓶颈。然而，**如果是在上传图片或视频**，即客户端向服务器传送大量数据时，服务器的接收窗口又可能成为制约因素。不管怎样，如果其中一端跟不上数据传输，那它可以向发送端通告一个较小的窗口。**假如窗口为零，则意味着必须由应用层先清空缓冲区，才能再接收剩余数据？？**。这个过程贯穿于每个 TCP 连接的整个生命周期：**每个 ACK 分组都会携带相应的最新 rwnd值**，以便两端动态调整数据流速，使之适应发送端和接收端的容量及处理能力。

3.2 慢启动 

尽管 TCP 有了流量控制机制，流量控制确实可以防止发送端向接收端过多发送数据，但是发送端和接收端在连接建立之初互相都被识别为潜在网络，谁也不知道可用带宽是多少，因此需要一个估算机制，然后还要根据网络中不断变化的条件而动态改变速度。

所谓的慢启动，其实颜如其名，通过一开始设置较小的阻塞窗口，每次成功接收数据帧后便将窗口大小翻倍或者按照其他方法进行递增，直到发生丢包情况。那么说明发生了拥塞，就再进行减小窗口的操作。


```
/Page38  example
1. 慢启动导致客户端与服务器之间经过几百 ms 才能达到接近最大速度的问题，对于大型流式下载服务的影响倒不显著，因为慢启动的时间可以分摊到整个传输周期内消化掉。
2. 可是，对于很多 HTTP连接，特别是一些短暂、突发的连接而言，常常会出现还没有达到最大窗口请求就被终止的情况。换句话说，很多 Web 应用的性能经常受到服务器与客户端之间往返时间的制约。因为慢启动限制了可用的吞吐量，而这对于小文件传输非常不利。
```
**SSR**
除了调节新连接的传输速度，TCP 还实现了 SSR（Slow-Start Restart，慢启动重启）机制。这种机制会在连接空闲一定时间后重置连接的拥塞窗口。道理很简单，在连接空闲的同时，网络状况也可能发生了变化，为了避免拥塞，理应将拥塞窗口重置回“安全的”默认值。

**3.3 拥塞预防**

拥塞预防算法把**丢包作为网络拥塞的标志**，即路径中某个连接或路由器已经拥堵了，以至于必须采取删包措施。因此，必须调整窗口大小，以避免造成更多的包丢失，从而保证网络畅通。

重置拥塞窗口后，拥塞预防机制按照自己的算法来增大窗口以尽量避免丢包。某个时刻，可能又会有包丢失，于是这个过程再从头开始。如果你看到过 TCP 连接的吞吐量跟踪曲线，发现该曲线呈锯齿状，那现在就该明白为什么了。这是拥塞控制和预防算法在调整拥塞窗口，进而消除网络中的丢包问题。

**TCP 比例降速**
确定丢包恢复的最优方式并不容易。如果太激进，那么间歇性的丢包就会对整个连接的吞吐量造成很大影响。而如果不够快，那么还会继续造成更多分组丢失。

最初，TCP 使用 AIMD（Multiplicative Decrease and Additive Increase，倍减加增）算法，即发生丢包时，先将拥塞窗口减半，然后每次往返再缓慢地给窗口增加一个固定的值。不过，很多时候 AIMD 算法太过保守，PRR(Proportional Rate Reduction，比例降速)就是 RFC 6937 规定的一个新算法，其目标就是改进丢包后的恢复速度

---

**3.3** 时延带宽积
TCP 内置的拥塞控制和预防机制对性能还有另一个重要影响：发送端和接收端理想的窗口大小，一定会因往返时间及目标传输速率而变化。

为什么？我们知道，发送端和接收端之间在途未确认的最大数据量，取决于拥塞窗口（cwnd）和接收窗口（rwnd）的最小值。接收窗口会随每次 ACK 一起发送，而拥塞窗口则由发送端根据拥塞控制和预防算法动态调整。

无论发送端发送的数据还是接收端接收的数据超过了未确认的最大数据量，都必须停下来等待另一方 ACK确认某些分组才能继续。要等待多长时间呢？取决于往返时间！
- BDP（Bandwidth-delay product，带宽延迟积）
数据链路的容量与其端到端延迟的乘积。这个结果就是任意时刻处于在途未确认状态的最大数据量。


```
样例推导 ：
1. 通过接收发送窗口数计算不发生阻塞的最小速度
2. 通过当前带宽计算允许的最大窗口数
```
好在窗口大小的协商与调节由网络栈自动控制，应该会自动调整。但尽管如此，窗口大小有时候仍然是 TCP 性能的限制因素。如果你怎么也想不通在高速连接的客户端与服务器之间，实际传输速度只有可用带宽的几分之一，那窗口大小很可能就是罪魁祸首。要么因为某一饱和端通告的接收窗口很小，要么因为网络拥堵和丢包导致拥塞窗口重置，更可能因为流量增长过快导致对连接吞吐量施加了限制。

**4. 队首阻塞**
TCP 在不可靠的信道上实现了可靠的网络传输。基本的分组错误检测与纠正、按序交付、丢包重发，以及保证网络最高效率的流量控制、拥塞控制和预防机制，让TCP 成为大多数网络应用中最常见的传输协议。

**每个 TCP 分组都会带着一个唯一的序列号被发出**，而所有分组必须按顺序传送到接收端。如果中途有一个分组没能到达接收端，那么后续分组必须保存在接收端的 TCP 缓冲区，等待丢失的分组重发并到达接收端。这一切都发生在 TCP 层，应用程序对 TCP 重发和缓冲区中排队的分组一无所知，必须等待分组全部到达才能访问数据。在此之前，应用程序只能在通过套接字读数据时感觉到延迟交付。这种效应称为 TCP 的队首（HOL，Head of Line）阻塞。

**队首阻塞**造成的延迟可以让我们的应用程序**不用关心分组重排和重组**，从而让**代码保持简洁**。然而，代码简洁也要付出代价，那就是**分组到达时间会存在无法预知的延迟变化**。这个时间变化通常被称为**抖动**，也是影响应用程序性能的一个主要因素。

有些应用程序可能并不需要可靠的交付或者不需要按顺序交付。比如，每个分组都是独立的消息，那么按顺序交付就没有任何必要。而且，如果每个消息都会覆盖之前的消息，那么可靠交付同样也没有必要了。这个时候UDP会成为更好的选择。

**5. 针对TCP的优化建议**

TCP 是一个自适应的、对所有网络节点一视同仁的、最大限制利用底层网络的协议。...尽管如此，而且每个算法和反馈机制的具体细节可能会继续发展，但核心原理以及它们的影响是不变的：
- TCP 三次握手增加了整整一次往返时间；
- TCP 慢启动将被应用到每个新连接；
- TCP 流量及拥塞控制会影响所有连接的吞吐量；
- TCP 的吞吐量由当前拥塞窗口大小控制。

**5.1 服务器配置调优**
- 让你的服务器跟上时代是优化发送端和接收端 TCP 栈的首要措施。

有了最新的内核，我们推荐你遵循如下最佳实践来配置自己的服务器：
- 增大TCP的初始拥塞窗口

加大起始拥塞窗口可以让 TCP 在第一次往返就传输较多数据，而随后的速度提升也会很明显。对于突发性的短暂连接，这也是特别关键的一个优化。
- 慢启动重启

在连接空闲时禁用慢启动可以改善瞬时发送数据的长 TCP 连接的性能。
- 窗口缩放（RFC1323）

启用窗口缩放可以增大最大接收窗口大小，可以让高延迟的连接达到更好吞吐量。
- TCP快速打开

在某些条件下，允许在第一个SYN分组中发送应用程序数据。TFO（TCP Fast Open，TCP快速打开）是一种新的优化选项，需要客户端和服务器共同支持。为此，首先要搞清楚你的应用程序是否可以利用这个特性。

**5.2　应用程序行为调优**
调优 TCP 性能可以让服务器和客户端之间达到最大吞吐量和最小延迟。而应用程序如何使用新的或已经建立的 TCP 连接同样也有很大的关系。
- 再快也快不过什么也不用发送，能少发就少发。
- 我们不能让数据传输得更快，但可以让它们传输的距离更短。
- 重用 TCP 连接是提升性能的关键。
当然，***消除不必要的数据传输本身就是很大的优化***。

比如，**减少下载不必要的资源，或者通过压缩算法把要发送的比特数降到最低**。

然后，**通过在不同的地区部署服务器（比如，使用 CDN），把数据放到接近客户端的地方，可以减少网络往返的延迟，从而显著提升 TCP 性能**。

最后，**尽可能重用已经建立的 TCP 连接，==把慢启动和其他拥塞控制机制的影响降到最低==**。

**5.3　性能检查清单**
- 把服务器内核升级到最新版本（Linux：3.2+）；
- 确保 cwnd 大小为 10；
- 禁用空闲后的慢启动；
- 确保启动窗口缩放；
- 减少传输冗余数据；
- 压缩要传输的数据；
- 把服务器放到离用户近的地方以减少往返时间；
- 尽最大可能重用已经建立的 TCP 连接。

## UDP协议的构成 ##
数据报（datagram）和分组（packet）是两个经常被人混用的词，实际上它们还是有区别的。分组可以用来指代任何格式化的数据块，而数据报则通常只用来描述那些通过不可靠的服务传输的分组，既不保证送达，也不发送失败通知。正因为如此，很多场合下人们都把 UDP 中 User（用户）的 U，改成 Unreliable（不可靠）的 U，于是 UDP 就成了“不可靠数据报协议”（Unreliable Datagram Protocol）。这也是为什么把UDP分组称为数据报更为恰当的原因。
**1. 无协议服务**
IP 层的主要任务就是按照地址从源主机向目标主机发送数据报。

```
注意，数据报这个词暗示了一个重要的信息：IP 层不保证消息可靠的交付，也不发送失败通知，实际上是把底层网络的不可靠性直接暴露给了上一层。
```
UDP 协议会用自己的分组结构封装用户消息，它只增加了 4 个字段：源端口、目标端口、分组长度和校验和。这样，当 IP 把分组送达目标主机时，该主机能够拆开 UDP 分组，根据目标端口找到目标应用程序，然后再把消息发送过去。仅此而已。

事实上，**UDP 数据报中的源端口和校验和字段都是可选的**。**IP 分组的首部也有校验和**，应用程序可以忽略 UDP 校验和。也就是说，所有错误检测和错误纠正工作*都可以委托给上层的应用程序*。说到底，UDP 仅仅是在 IP 层之上通过嵌入应用程序的源端口和目标端口，提供了一个“应用程序多路复用”机制。明白了这一点，就可以总结一下 UDP 的无服务是怎么回事了。

- 不保证消息交付
不确认，不重传，无超时。
- 不保证交付顺序
不设置包序号，不重排，不会发生队首阻塞。
- 不跟踪连接状态
不必建立连接或重启状态机。
- 不需要拥塞控制
不内置客户端或网络反馈机制。

**TCP 是一个面向字节流的协议**，能够以多个分组形式发送应用程序消息，且对分组中的消息范围没有任何明确限制。因此，**连接的两端存在一个连接状态，每个分组都有序号，丢失还要重发，并且要按顺序交付**。

相对来说，**UDP 数据报有明确的限制**：数据报必须封装在 IP 分组中，应用程序必须读取完整的消息。换句话说，**数据报不能分片**。


```
UDP 是一个简单、无状态的协议，适合作为其他上层应用协议的辅助。实际上，这个协议的所有决定都需要由上层的应用程序作出。
```
**2. UDP与网络地址转换器**
IPv4 地址只有 32 位长，因而最多只能提供 42.9 亿个唯一 IP 地址。作为解决 IPv4 地址即将耗尽的一个临时性方案，IP 网络地
址转换器（NAT，Network Address Translator）规范出台了
**2.1 连接状态超时**
NAT 转换的问题（至少对于 UDP 而言）在于必须维护一份精确的路由表才能保证
数据转发。NAT 设备依赖连接状态，而 UDP 没有状态。

NAT 转换的问题（至少对于 UDP 而言）在于必须维护一份精确的路由表才能保证数据转发。NAT 设备依赖连接状态，而 UDP 没有状态。这种根本上的错配是很多UDP 数据报传输问题的总根源。况且，客户端前面有很多个 NAT 设备的情况也不鲜见，问题由此进一步恶化了。

每个 TCP 连接都有一个设计周密的协议状态机，从握手开始，然后传输应用数据，最后通过明确的信号确认关闭连接。在这种设计下，路由设备可以监控连接状态，根据情况创建或删除路由表中的条目。而 UDP 呢，没有握手，没有连接终止，实际根本没有可监控的连接状态机。

发送出站 UDP 不费事，但路由响应却需要转换表中有一个条目能告诉我们本地目标主机的 IP 和端口。因此，转换器必须保存每个 UDP 流的状态，而 UDP 自身却没有状态。

**2.2 NAT穿透**
不可预测的连接状态处理是 NAT 设备带来的一个严重问题，但更为严重的则是很多应用程序根本就不能建立 UDP 连接。尤其是 P2P 应用程序，涉及 VoIP、游戏和文件共享等，它们客户端与服务器经常需要角色互换，以实现端到端的双向通信。

**不可预测的连接状态处理**是 NAT 设备带来的一个严重问题，但更为严重的则是**很多应用程序根本就不能建立 UDP 连接**。尤其是 P2P 应用程序，涉及 VoIP、游戏和文件共享等，它们客户端与服务器经常需要角色互换，以实现端到端的双向通信。

个人理解：由于UDP传输不具备类似反馈的调节机制，所以跟路由表的更新其实不相匹配，同理跟NAT的映射规则也应该是不相匹配的，在这种请况下，很有可能导致UDP无法正常通信，频繁丢包的情况发生。（知道外网 IP 地址还不是实现 UDP 传输的充分条件。任何到达 NAT 设备外网 IP的分组还必须有一个目标端口，而且 NAT 转换表中也要有一个条目可以将其转换为内部主机的 IP 地址和端口号。如果没有这个条目（通常是从外网传数据进来），那到达的分组就会被删除。此时的 NAT 设备就像一个分组过滤器，除非用户通过端转发（映射）或类似机制配置过，否则它无法确定将 . 分组发送给哪台内部主机。）
为解决 UDP 与 NAT的这种不搭配，人们发明了**很多穿透技术（TURN、STUN、ICE）**，**用于在 UDP 主机之间建立端到端的连接**。

**2.3 STUN、TURN与ICE**
//TODO

STUN（Session Traversal Utilities for NAT）是一个协议（RFC 5389），可以让应用程序发现网络中的地址转换器，发现之后进一步取得为当前连接分配的外网 IP 地址和端口。

假设 STUN 服务器的 IP 地址已知（通过 DNS 查找或手工指定），应用程序首先向STUN 服务器发送一个绑定请求。然后，STUN 服务器返回一个响应，其中包含在外网中代表客户端的 IP 地址和端口号。这种简单的方式解决了前面讨论的一些问题：
- 应用程序可以获得外网 IP和端口，并利用这些信息与对端通信；
- 发送到 STUN 服务器的出站绑定请求将在通信要经过的 NAT中建立路由条目，使得到达该 IP 和端口的入站分组可以找到内网中的应用程序；
- STUN 协议定义了一个简单 keep-alive 探测机制，可以保证 NAT 路由条目不超时。

有了这个机制，两台主机端需要通过 UDP 通信时，它们首先都会向各自的 STUN服务器发送绑定请求，然后分别使用响应中的外网 IP 地址和端口号交换数据。

---

但是在实际中，STUN并不能适应所有的网络配置，在企业网中甚至UDP直接会被屏蔽，在这种情况下：在 STUN 失败的情况下，我们还可以使用 TURN协议作为后备。**TURN 可以在最坏的情况下跳过 UDP 而切换到 TCP**

---

ICE（Interactive Connectivity Establishment）协议。ICE 规定了一套方法，致力于在通信各端之间建立一条最有效的通道：能直连就直连，必要时 STUN 协商，再不行使用 TURN。

**3. 针对UDP的优化建议**

UDP 是一个简单常用的协议。特色在于有些功能：**连接状态、握手、重发、重组、重排、拥塞控制、拥塞预防、流量控制，甚至可选的错误检测，统统没有**。这个面向消息的最简单的传输层在提供灵活性的同时，也给实现者带来了麻烦。你的应用程序很可能需要从头实现上述几个或者大部分功能，而且每项功能都必须保证与网络中的其他主机和协议和谐共存。

与内置流量和拥塞控制以及拥塞预防的 TCP 不同**，UDP 应用程序必须自己实现这些机制**。拥塞处理做得不到位的 UDP 应用程序很容易堵塞网络，造成网络性能下降，严重时还会导致网络拥塞崩溃。

对设计单播 UDP 应用程序给出了很多设计建议，简述如下：
- 应用程序必须容忍各种因特网路径条件；
- 应用程序应该控制传输速度；
- 应用程序应该对所有流量进行拥塞控制；
- 应用程序应该使用与 TCP 相近的带宽；
- 应用程序应该准备基于丢包的重发计数器；
- 应用程序应该不发送大于路径 MTU 的数据报；
- 应用程序应该处理数据报丢失、重复和重排；
- 应用程序应该足够稳定以支持 2 分钟以上的交付延迟；
- 应用程序应该支持 IPv4 UDP 校验和，必须支持 IPv6 校验和；
- 应用程序可以在需要时使用 keep-alive（最小间隔 15 秒）。

## 传输层安全（TLS）##
SSL（Secure Sockets Layer，安全套接字层）协议最初是网景公司为了保障网上交易安全而开发的，该协议**通过加密来保护客户个人资料**，**通过认证和完整性检查来确保交易安全**。为达到这个目标，SSL 协议在直接**位于** TCP 上一层的**应用层**被实现。

**1. 加密、身份验证与完整性**
TLS 协议的目标是为在它之上运行的应用提供三个基本服务：加密、身份验证和数据完整性。从技术角度讲，并不是所有情况下都要同时使用这三个服务。

- 加密:
混淆数据的机制
- 身份验证:
验证身份标识有效性的机制
- 完整性:
检测消息是否被篡改或伪造的机制

为了建立加密的安全数据通道，连接双方必须就加密数据的**密钥套件和密钥**协商一致 。TLS 协议规定了一套严密的**握手程序用于交换这些信息**,这套系统可以让通信双方不必事先“认识”即可商定共
享的安全密钥，而且协商过程还是通过非加密通道完成的。

**握手过程中**，TLS 协议还允许通信两端互相验明正身。在浏览器中，验证机制允许客户端验证服务器就是它想联系的那个（比如，银行），而不是通过名字或 IP 地址伪装的目标。这个验证首先需要建立“认证机构信任链”(代表，信任证书？)。









